{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7287e76c",
   "metadata": {},
   "source": [
    "# SPFlow 1.0.0 Design Concept\n",
    "\n",
    "Design basis:\n",
    "* Easy-to use and extend\n",
    "<br>\n",
    "\n",
    "* Functional design (using dispatch)\n",
    "<br>\n",
    "\n",
    "* Modular building blocks that can be stacked and nested\n",
    "    * Allows for quick design of large models\n",
    "    * Allows to combine existing or extend existing models\n",
    "<br>\n",
    "\n",
    "\n",
    "* Support multiple back-end with one-to-one mappings between backends\n",
    "    * Allows for easy model sharing and conversion to favorite back-end\n",
    "    * Base back-end should use explicit node modules as lowest basic blocks\n",
    "        * E.g allows alternative node-wise evaluations (e.g. for computing p-values)\n",
    "    * Other back-ends may use optimized modules (i.e. implicit nodes)\n",
    "        * Still need to be mappable to base-backend"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a744d5de",
   "metadata": {},
   "source": [
    "![overview](uml/all.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8ff5732",
   "metadata": {},
   "source": [
    "##### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f95bd2b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any, List, Tuple, Set, Dict, Union, Optional\n",
    "from abc import ABC, abstractmethod, abstractproperty\n",
    "from dataclasses import dataclass\n",
    "import itertools\n",
    "from multipledispatch import dispatch\n",
    "\n",
    "import numpy as np\n",
    "from scipy.stats import norm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a9f641f",
   "metadata": {},
   "source": [
    "## NetworkType Class\n",
    "\n",
    "* All network types (e.g. `SPN`, `BN`, ...) inherit from it\n",
    "* Network types do not need to actually implement anything\n",
    "* Simply needed to dispatch on network type objects (e.g. for computing scopes, likelihoods, sampling etc.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8df4f45c",
   "metadata": {},
   "source": [
    "![network_type](uml/network_type.svg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dac9e630",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NetworkType(ABC):\n",
    "    \"\"\"Abstract base class for network types.\"\"\"\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16a24395",
   "metadata": {},
   "source": [
    "#### SPN Network Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "90a25bf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SPN(NetworkType):\n",
    "    \"\"\"Sum-Product Network (SPN) network type.\"\"\"\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e5d4720",
   "metadata": {},
   "source": [
    "\n",
    "## Scope Class\n",
    "\n",
    "Attributes:\n",
    "* `scope`: set of indices (scope)\n",
    "* `ntype`: network type this scope is in reference to\n",
    "\n",
    "The class can, for example, overwride `__add__` operator to merge scopes based on their network types.\n",
    "\n",
    "**TODO**:\n",
    "* Network types and modules may have to check whether or not this merging is valid (e.g. sum- vs product-nodes)\n",
    "* Conditional/evidence variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf89c617",
   "metadata": {},
   "source": [
    "![scope](uml/scope.svg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7a517776",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Scope:\n",
    "    \"\"\"Class representing Variable scopes.\"\"\"\n",
    "    def __init__(self, ntype: NetworkType, query: Union[Set[int], List[int]], evidence: Optional[Union[Set[int], List[int]]]=None) -> None:\n",
    "\n",
    "        if evidence is None:\n",
    "            evidence = set()\n",
    "\n",
    "        query = set(query)\n",
    "        evidence = set(evidence)\n",
    "\n",
    "        if not query.isdisjoint(evidence):\n",
    "            raise ValueError(\"Specified sets of query and evidence variables are not disjoint.\")\n",
    "\n",
    "        self.query = query\n",
    "        self.evidence = evidence\n",
    "        self.network_type = ntype\n",
    "\n",
    "    def __repr__(self) -> str:\n",
    "        return \"Scope({}|{})\".format(self.query if self.query else \"{}\", self.evidence if self.evidence else \"{}\")\n",
    "\n",
    "    def __add__(self, other: \"Scope\") -> \"Scope\":\n",
    "        \"Dispatches scope merging based on network types.\"\n",
    "        return merge_scope(self, other)\n",
    "    \n",
    "    def __len__(self) -> int:\n",
    "        return len(self.query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99f8b864",
   "metadata": {},
   "source": [
    "Merging scopes is automatically dispatched to merging scopes based on their respective network type contexts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2c3bdca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dispatch(Scope, Scope)\n",
    "def merge_scope(scope1: Scope, scope2: Scope) -> Scope:\n",
    "    \"\"\"Generic intermediate function to dispatch merging based on network types.\"\"\"\n",
    "    return merge_scope(scope1.network_type, scope1, scope2.network_type, scope2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fa02334",
   "metadata": {},
   "source": [
    "To register a new merge operation (e.g. between two `SPN` scopes): dispatch appropriate function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b8318e31",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dispatch(SPN, Scope, SPN, Scope)\n",
    "def merge_scope(ntype1: SPN, scope1: Scope, ntype2: SPN, scope2: Scope) -> Scope:\n",
    "    \"\"\"Merges two SPN scopes.\"\"\"\n",
    "    return Scope(SPN(), set.union(scope1.query, scope2.query), set.union(scope1.evidence, scope2.evidence))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5c0565d",
   "metadata": {},
   "source": [
    "##### Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "25f70d69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scope1: Scope({0, 1}|{})\n"
     ]
    }
   ],
   "source": [
    "s1 = Scope(SPN(), [0,1])\n",
    "print(\"Scope1:\", s1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "45260d44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scope 2: Scope({1, 2, 3}|{})\n"
     ]
    }
   ],
   "source": [
    "s2 = Scope(SPN(), [1,2,3])\n",
    "print(\"Scope 2:\", s2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c389be70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged scope: Scope({0, 1, 2, 3}|{})\n"
     ]
    }
   ],
   "source": [
    "s = s1+s2\n",
    "print(\"Merged scope:\", s)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80aa12cc",
   "metadata": {},
   "source": [
    "### Scope Array\n",
    "\n",
    "Array class inheriting from `np.ndarray`. Alterantively one can just pass `dtype=Scope` as an argument to `np.ndarray`.\n",
    "\n",
    "Can store scopes with different scope length in an array format that can easily be propagated through a model (e.g. similar to likelihood values)\n",
    "\n",
    "**NOTE**: creating arrays/tensors with `Scope`-elements might not be possible in all backends. In any case (since scope outputs for modules are not multi-dimensional), a list with `Scope`s could be returned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "77f6234c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ScopeArray(np.ndarray):\n",
    "    \"\"\"Numpy array with Scope object elements.\"\"\"\n",
    "    def __new__(cls, data) -> np.ndarray:\n",
    "        return np.array(data, dtype=Scope)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f23867ea",
   "metadata": {},
   "source": [
    "##### Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "71bd5021",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([Scope({0, 1}|{}), Scope({1, 2, 3}|{})], dtype=object)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ScopeArray([s1, s2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cd3dd62",
   "metadata": {},
   "source": [
    "Also allows to use appropriate numpy-operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d91da852",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Scope({0, 1, 2, 3}|{})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ScopeArray([s1, s2]).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05895e97",
   "metadata": {},
   "source": [
    "## Module Class\n",
    "\n",
    "Every module inherits from this class.\n",
    "\n",
    "Each module must also implement `__len__(self)` to return the number of (implicit or explicit) output node of this module."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98b9a055",
   "metadata": {},
   "source": [
    "![module](uml/module.svg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "745a546c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Module(ABC):\n",
    "    \"\"\"Abstract base class for modules.\n",
    "    \n",
    "    Args:\n",
    "        children: list of child modules (may be empty for terminal modules).\n",
    "    \"\"\"\n",
    "    def __init__(self, children: Optional[List[\"Module\"]]=None) -> None:\n",
    "        \n",
    "        if children is None:\n",
    "            children = []\n",
    "        \n",
    "        # set child modules\n",
    "        self.children = children\n",
    "        \n",
    "        # infer number of inputs from children (and their numbers of outputs)\n",
    "        child_num_outputs = [child.n_out for child in self.children]\n",
    "        child_cum_outputs = np.cumsum(child_num_outputs)\n",
    "        \n",
    "        self.n_in = sum(child_num_outputs, 0)\n",
    "\n",
    "        # compute conversion from input ids corresponding child and output id (Saves computation at run-time)\n",
    "        self.input_to_output_id_dict = {}\n",
    "        \n",
    "        for input_id in range(self.n_in):\n",
    "            # get child module for corresponding input\n",
    "            child_id = np.sum(child_cum_outputs <= input_id, axis=0).tolist()\n",
    "            # get output id of child module for corresponding input\n",
    "            output_id = input_id-(child_cum_outputs[child_id]-child_num_outputs[child_id])\n",
    "            \n",
    "            self.input_to_output_id_dict[input_id] = (child_id, output_id)\n",
    "\n",
    "    @abstractproperty\n",
    "    def n_out(self) -> int:\n",
    "        \"\"\"Specifies the number of outputs, i.e. (implicit of explicit) output nodes.\"\"\"\n",
    "        pass\n",
    "\n",
    "    def input_to_output_id(self, input_id) -> Tuple[int, int]:\n",
    "        \"\"\"Helper method to convert an input id to a corresponding child and child output id.\"\"\"\n",
    "        return self.input_to_output_id_dict[input_id]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "766697ba",
   "metadata": {},
   "source": [
    "# Dispatching\n",
    "\n",
    "Errors/exceptions during dispatching are hard to trace back. Here, we followed the convention to name the `Module` argument (that is dispatched on) after the corresponding dispatched class. This signature shows up in the error traceback and helps debugging.\n",
    "\n",
    "**TODO**: one might provide a better trace-back via decorators?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e92c724f",
   "metadata": {},
   "source": [
    "## Sampling\n",
    "\n",
    "Sampling should return an array in a form that could immediately be used to infer likelihoods of that same module. That entails, that the RVs are in ascending order and that no RVs are skipped (e.g. sampling over a scope of `[0,2,5]` should return an array of size `(n,6)` to accommodate for all scope RVs at their respective indices while leaving all other entries as NaNs; `n` is the number of samples).\n",
    "\n",
    "API:\n",
    "- `sample(module)` should return return a single sample (size `(1,m)`)\n",
    "- `sample(module, n)` should return return `n` samples (size `(n,m)`)\n",
    "- `sample(module, array)` should fill the specified array in-place and return it as well (array must be of appropriate size). This also allows to specify incomplete data that is not replaced during sampled and whose likelihoods are taken into account while sampling.|"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a0249ce",
   "metadata": {},
   "source": [
    "When sampling for multiple instances, we need to keep track which modules are supposed to sample which instances.\n",
    "\n",
    "Example:\n",
    "![sampling_context_example](img/sampling_context_example.drawio.svg)\n",
    "In this case, the sum node samples a branch (B or C) for each instance, so A and B are sampling into the same data array, but get different instances to sample.\n",
    "\n",
    "In the multi-output case (i.e. modules, see below) one additionally needs to specify which outputs are supposed to be sampled.\n",
    "\n",
    "Example:\n",
    "![sampling_context_example](img/sampling_context_example_2.drawio.svg)\n",
    "Here, we essentially have the same graph as above, but `sample(...)` is called on the same child module for all instances."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "868c9843",
   "metadata": {},
   "source": [
    "`SamplingContext` class to track which instances to sample and which module outputs to sample from. Keeps a list of instance ids to fill with samples and corresponding output ids to sample from for these instances for a given module."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d670f0f",
   "metadata": {},
   "source": [
    "![sampling_context](uml/sampling_context.svg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "62a83fe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SamplingContext:\n",
    "    \"\"\"Keeps track of instance ids to sample and which output ids to sample from (relevant for modules with multiple outputs).\n",
    "    \n",
    "    Args:\n",
    "        instance_ids: list of ints representing the instances to sample.\n",
    "        output_ids: list of lists of ints representing the output ids for the corresponding instances to sample from (relevant for multi-output module).\n",
    "                    As a shorthand, '[]' implies to sample from all outputs for a given instance id.\n",
    "    \"\"\"\n",
    "    def __init__(self, instance_ids: List[int], output_ids: Optional[List[List[int]]]=None) -> None:\n",
    "\n",
    "        if output_ids is None:\n",
    "            # assume sampling over all outputs (i.e. [])\n",
    "            output_ids = [[] for _ in instance_ids]\n",
    "        \n",
    "        if (len(output_ids) != len(instance_ids)):\n",
    "            raise ValueError(f\"Number of specified instance ids {len(instance_ids)} does not match specified number of output ids {len(output_ids)}.\")\n",
    "\n",
    "        self.instance_ids = instance_ids\n",
    "        self.output_ids = output_ids\n",
    "\n",
    "    def select(self, ids: List[int]) -> \"SamplingConctext\":\n",
    "        \"\"\"Selects a subset of the instance ids and their corresponding output ids in a new sampling context object.\"\"\"\n",
    "        selection = [pair for i, pair in enumerate(zip(self.instance_ids, self.output_ids)) if i in ids]\n",
    "        return SamplingContext(*tuple(list(item) for item in zip(*selection)))\n",
    "\n",
    "    def append(self, instance_ids: List[int], output_ids: List[List[int]]) -> None:\n",
    "        \"\"\"Adds new instance ids and corresponding output ids to the sampling context.\"\"\"\n",
    "        if(len(instance_ids) != len(output_ids)):\n",
    "            raise ValueError(f\"Number of specified instance ids {len(instance_ids)} does not match specified number of output ids {len(output_ids)}.\")\n",
    "        \n",
    "        self.instance_ids += instance_ids\n",
    "        self.output_ids += output_ids\n",
    "\n",
    "    def remove(self, ids: List[int]) -> None:\n",
    "        \"\"\"Removes a subset of the instance ids and their corresponding output ids from the sampling context object.\"\"\"\n",
    "        selection = [pair for i, pair in enumerate(zip(self.instance_ids, self.output_ids)) if i not in ids]\n",
    "        self.instance_ids, self.output_ids = tuple(list(item) for item in zip(*selection))\n",
    "    \n",
    "    def is_valid(self, data: Optional[np.ndarray]=None, module: Optional[Module]=None) -> bool:\n",
    "        \"\"\"Returns a boolean whether or not the sampling context object is valid. Additionally, a data array and a module may be specified).\"\"\"\n",
    "        \n",
    "        # check if there are any duplicate instance ids\n",
    "        if len(set(self.instance_ids)) != len(self.instance_ids):\n",
    "            return False\n",
    "        \n",
    "        # validate individual instance ids\n",
    "        for instance_id in self.instance_ids:\n",
    "            # check if all instance ids are greater or equal to 0\n",
    "            if instance_id < 0:\n",
    "                return False\n",
    "            # if a data array is specified, then also check if the instance ids are valid for it\n",
    "            if (data is not None) and (instance_id >= data.shape[0]):\n",
    "                return False\n",
    "        \n",
    "        # check if number of output ids matches number of input ids\n",
    "        if len(self.instance_ids) != len(self.output_ids):\n",
    "            return False\n",
    "        \n",
    "        # check if any output id lists contain duplicates\n",
    "        for out_ids in self.output_ids:\n",
    "            if len(set(out_ids)) != len(out_ids):\n",
    "                return False\n",
    "        \n",
    "        # validate individual output ids\n",
    "        for out_ids in self.output_ids:\n",
    "            for out_id in out_ids:\n",
    "                # Check if all output ids are greater of equal to 0\n",
    "                if out_id < 0:\n",
    "                    return False\n",
    "                # if a module is specified, then also check if the output ids are valid indices for it\n",
    "                if (module is not None) and (out_id >= module.n_out):\n",
    "                    return False\n",
    "        \n",
    "        return True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49558c40",
   "metadata": {},
   "source": [
    "##### Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f7cdae06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 2, 4, 6] [[1], [], [], [4]]\n"
     ]
    }
   ],
   "source": [
    "sc = SamplingContext([0,2,4,6],[[1],[],[],[4]])\n",
    "print(sc.instance_ids, sc.output_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4341d11f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 6] [[], [4]]\n"
     ]
    }
   ],
   "source": [
    "# select certain instance ids (e.g. to pass to a child module for sampling)\n",
    "sc2 = sc.select([1,3])\n",
    "print(sc2.instance_ids, sc2.output_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "20cabf25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 4] [[1], []]\n"
     ]
    }
   ],
   "source": [
    "# remove certain instance ids\n",
    "sc.remove([1,3])\n",
    "print(sc.instance_ids, sc.output_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeeeac51",
   "metadata": {},
   "source": [
    "Dispatch sampling for all modules without specified data tensor (see API-notes above)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d2f12c0",
   "metadata": {},
   "source": [
    "## Dispatch Cache\n",
    "\n",
    "Dispatching function calls (e.g. `likelihood`), might require to cache results to avoid redundant computations.\n",
    "\n",
    "![dispatch_cache](uml/dispatch_cache.svg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6071f6e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict\n",
    "import numpy as np\n",
    "\n",
    "class DispatchCache(dict):\n",
    "    def __init__(self):\n",
    "        self.likelihood = {}\n",
    "        self.sample = {}\n",
    "        self.scope = {}\n",
    "        self._valid_keys = ['likelihood', 'sample', 'scope']\n",
    "    \n",
    "    def __contains__(self, key: Module) -> bool:\n",
    "        return any(key in getattr(self, k) for k in self._valid_keys)\n",
    "    \n",
    "    def __getitem__(self, key: Module) -> Dict[str, np.ndarray]:\n",
    "        if not isinstance(key, Module):\n",
    "            raise KeyError(f\"Cache key is of type {type(key)}, but is expected to be of type {Module}.\")\n",
    "\n",
    "        cach_values = {k: getattr(self, k)[key] for k in self._valid_keys if key in getattr(self, k)}\n",
    "\n",
    "        if(cach_values):\n",
    "            return cach_values\n",
    "        else:\n",
    "            raise KeyError(f\"{key} not found in cache.\")\n",
    "    \n",
    "    def __setitem__(self, key: Module, values: Dict[str, np.ndarray]) -> None:\n",
    "        for k in values.keys():\n",
    "            if k not in self._valid_keys:\n",
    "                raise KeyError(f\"Value dictionary for setting dispatch cache contains invalid key '{k}'.\")\n",
    "\n",
    "        for k in self._valid_keys:\n",
    "            if k in values:\n",
    "                getattr(self, k)[key] = values[k]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "537adca8",
   "metadata": {},
   "source": [
    "# Dispatch Context\n",
    "\n",
    "Besides a cache, modules might require (or allow) additional arguments for dispatched function calls. To avoid messy function signatures and an overly complicated argument management by the user, it might be wiser to collect everything in a single class (called `DispatchContext` here).\n",
    "\n",
    "![dispatch_context](uml/dispatch_context.svg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a89e0711",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any\n",
    "\n",
    "class DispatchContext(dict):\n",
    "    def __init__(self):\n",
    "        self.cache = DispatchCache()\n",
    "        self.args = {}\n",
    "        self._valid_keys = ['cache', 'args']\n",
    "\n",
    "    def __contains__(self, key: Module) -> bool:\n",
    "        return (key in self.cache) or (key in self.args)\n",
    "\n",
    "    def __getitem__(self, key: Module) -> Dict[str, Any]:\n",
    "        \n",
    "        values = {}\n",
    "        \n",
    "        if key in self.cache:\n",
    "            values['cache'] = self.cache[key]\n",
    "        if key in self.args:\n",
    "            values['args'] = self.args[key]\n",
    "        \n",
    "        if values:\n",
    "            return values\n",
    "        else:\n",
    "            raise KeyError(f\"{key} not found in dispatch context.\")\n",
    "\n",
    "    def __setitem__(self, key: Module, values: Dict[str, Any]) -> None:\n",
    "        \n",
    "        for k in values.keys():\n",
    "            if k not in self._valid_keys:\n",
    "                raise KeyError(f\"Value dictionary for setting dispatch context contains invalid key '{k}'.\")\n",
    "        \n",
    "        for k in values.keys():\n",
    "            getattr(self, k)[key] = values[k]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9322c77c",
   "metadata": {},
   "source": [
    "### Memoization Decorator\n",
    "\n",
    "E.g. can wrap the `likelihood` function and automatically check the cache and re-use or fill it.\n",
    "\n",
    "**NOTE**: the `memoize` decorate must come after the `dispatch` decorator (before in the decorator evaluation logic), so that the memoized version of the function is being dispatched!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2793e898",
   "metadata": {},
   "source": [
    "![memoize](uml/memoize.svg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3354a334",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import wraps\n",
    "\n",
    "def memoize(f):\n",
    "    \"\"\"Wraps a function to automatically check against a cache ('cache' keyword argument) using the first argument as the key.\n",
    "    If present, the cached value is returned, otherwise it is computed using the wrapped function stored in the cache.\n",
    "    \"\"\"\n",
    "    @wraps(f)\n",
    "    def memoized_f(*args, **kwargs):\n",
    "        \n",
    "        # ----- cache -----\n",
    "        \n",
    "        # first look in keyword arguments\n",
    "        if \"dispatch_ctx\" in kwargs and isinstance(kwargs[\"dispatch_ctx\"], DispatchContext):\n",
    "            cache = kwargs['dispatch_ctx'].cache\n",
    "        else:\n",
    "            # otherwise check positional argumentsw\n",
    "            candidates = [arg for arg in args if isinstance(arg, DispatchContext)]\n",
    "\n",
    "            if(len(candidates) > 1):\n",
    "                # if there are multiple candidates raise an error\n",
    "                raise ValueError(\"TODO: multiple candidates found.\")\n",
    "            elif candidates:\n",
    "                # otherwise if there is only one candidate, then use it\n",
    "                cache = candidates.pop().cache\n",
    "            else:\n",
    "                # otherwise create a new dispatch context\n",
    "                kwargs['dispatch_ctx'] = DispatchContext()\n",
    "                cache = kwargs['dispatch_ctx'].cache\n",
    "\n",
    "        # ----- module (cache key) -----\n",
    "        \n",
    "        # args contains key variable to be used for cache (assumes key variable is first positional argument to f)\n",
    "        if len(args) > 0:\n",
    "            key = args[0]\n",
    "        # key variable must be part of kwargs\n",
    "        else:\n",
    "            raise ValueError(\"No argument to cache against\")\n",
    "        \n",
    "        # get function-specific cache\n",
    "        f_cache = getattr(cache, f.__name__)\n",
    "\n",
    "        if key not in f_cache:\n",
    "            # compute result and update cache\n",
    "            f_cache[key] = f(*args, **kwargs)\n",
    "\n",
    "        return f_cache[key]\n",
    "    return memoized_f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "05f72cbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dispatch(Module, dispatch_ctx=DispatchContext)\n",
    "@memoize\n",
    "def sample(module: Module, dispatch_ctx: DispatchContext) -> np.ndarray:\n",
    "    \"\"\"Dispatches sampling a single instance from the module.\"\"\"\n",
    "    return sample(module, 1, dispatch_ctx=dispatch_ctx)\n",
    "\n",
    "@dispatch(Module, int, dispatch_ctx=DispatchContext, sampling_ctx=SamplingContext)\n",
    "@memoize\n",
    "def sample(module: Module, n_samples: int, dispatch_ctx: DispatchContext, sampling_ctx: SamplingContext=None) -> np.ndarray:\n",
    "    \"\"\"Creates an array for n samples and dispatches sampling to fill the array\"\"\"\n",
    "    if(not sampling_ctx):\n",
    "        # create sampling context (assume all instances are sampled from)\n",
    "        sampling_ctx = SamplingContext(list(range(n_samples)), [[] for _ in range(n_samples)])\n",
    "\n",
    "    # get module scope and largest random variable id\n",
    "    module_scope = scope(module).squeeze().tolist()\n",
    "    max_rv = max(module_scope.query) # TODO: include evidence?\n",
    "\n",
    "    # create appropriate data tensor to fill\n",
    "    data = np.full((n_samples,max_rv+1), float(\"nan\"))\n",
    "\n",
    "    # sample and fill data tensor\n",
    "    return sample(module, data, dispatch_ctx=dispatch_ctx, sampling_ctx=sampling_ctx)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2399ab05",
   "metadata": {},
   "source": [
    "## (Log-)Likelihood\n",
    "\n",
    "In general, we would like to offer both `likelihood` and `loglikelihood` routines. For better comprehension, we only implement `likelihood` in this module. Note, that we can easily implement one from the other by simply calling `log(..)` or `exp(..)`, respectively.\n",
    "\n",
    "API:\n",
    "- `likelihood(module, data)`: should return an array of the size `(n,1)`. `np.nan` values are marginalized over (not necessarily demonstrated here).\n",
    "- `likelihood(module, data, dict)`: specifies a dictionary (empty, partially or fully filled). For each module check if it is in the dictionary keys and reuses the stored value or computes it and updates the cache afterwards. The cache can then be reused for later calls (with the same data) or e.g. for the `sampling` function."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e029db37",
   "metadata": {},
   "source": [
    "## Node Modules\n",
    "\n",
    "Basic `LeafNode`,`SumNode` and `ProductNode` classes.\n",
    "\n",
    "Every class dispatches `likelihood(...)`, `scope(...)` and `sample(...)`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d7e4739",
   "metadata": {},
   "source": [
    "![nodes](uml/nodes.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0150f075",
   "metadata": {},
   "source": [
    "### Abstract Node Module\n",
    "\n",
    "Fixed outputs size (i.e. `__len__`) of 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d4b2bc19",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node(Module, ABC):\n",
    "    \"\"\"Represents basic nodes, i.e. the smallest building block for non-optimized networks.\"\"\"\n",
    "    @property\n",
    "    def n_out(self) -> int:\n",
    "        return 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec50abbf",
   "metadata": {},
   "source": [
    "### Leaf Nodes\n",
    "\n",
    "**Note**: `LeafNode` should actually be an abstract base class for leaf nodes to inherit from. In this example we simply implement `LeafNode` as a one-dimensional Gaussian distribution for demonstration purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7e8b36ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LeafNode(Node):\n",
    "    \"\"\"Basic univariate leaf node. Here, implemented as a Gaussian.\n",
    "\n",
    "    Args:\n",
    "        scope: scope of the distribution.\n",
    "        mean: mean of the distribution.\n",
    "        std: standard deviation of the distribution\n",
    "    \"\"\"\n",
    "    def __init__(self, scope: Scope, mean=0.0, std=1.0) -> None:\n",
    "        \n",
    "        if(len(scope) != 1):\n",
    "            raise ValueError(\"Scope to large for univariate leaf node.\")\n",
    "        \n",
    "        super(LeafNode, self).__init__()\n",
    "        \n",
    "        self.scope = scope\n",
    "        self.mean = mean\n",
    "        self.std = std\n",
    "        self.dist = norm(loc=mean, scale=std)\n",
    "\n",
    "@dispatch(LeafNode, dispatch_ctx=DispatchContext)\n",
    "@memoize\n",
    "def scope(leaf_node: LeafNode, dispatch_ctx: DispatchContext) -> ScopeArray:\n",
    "    \"\"\"Simply returns the scope of the module, since it's a leaf node.\"\"\"\n",
    "    return ScopeArray([[leaf_node.scope]])\n",
    "\n",
    "@dispatch(LeafNode, np.ndarray, dispatch_ctx=DispatchContext)\n",
    "@memoize\n",
    "def likelihood(leaf_node: LeafNode, data: np.ndarray, dispatch_ctx: DispatchContext) -> np.ndarray:\n",
    "    \"\"\"Returns the likelihood for each data instance. Marginalizes (likelihood of 1) for NaN values.\"\"\"\n",
    "    likelihoods = np.ones((data.shape[0], len(leaf_node.scope)))\n",
    "    inputs = data[:, list(leaf_node.scope.query)]\n",
    "\n",
    "    marg_ids = np.isnan(inputs).sum(axis=1) == len(leaf_node.scope)\n",
    "    likelihoods[~marg_ids, :] = leaf_node.dist.pdf(inputs[~marg_ids, :])\n",
    "\n",
    "    return likelihoods\n",
    "\n",
    "@dispatch(LeafNode, np.ndarray, dispatch_ctx=DispatchContext, sampling_context=SamplingContext)\n",
    "@memoize\n",
    "def sample(leaf_node: LeafNode, data: np.ndarray, dispatch_ctx: DispatchContext, sampling_ctx: Optional[SamplingContext]=None) -> np.ndarray:\n",
    "    \"\"\"Samples and fills the indices specified in the sampling context.\"\"\"\n",
    "\n",
    "    if sampling_ctx:\n",
    "        if not sampling_ctx.is_valid(data, leaf_node):\n",
    "            # invalid sampling context\n",
    "            raise ValueError(f\"Specified sampling context is invalid for specified data array and module.\")\n",
    "    else:\n",
    "        # create sampling context (assume all instances and all output nodes are to be used)\n",
    "        sampling_ctx = SamplingContext(list(range(data.shape[0])), [[] for _ in range(data.shape[0])]) \n",
    "\n",
    "    scope_vars = list(leaf_node.scope.query)\n",
    "\n",
    "    # sample ids (nan entries)\n",
    "    sample_ids = (np.isnan(data[:, scope_vars]).sum(axis=1) == len(scope_vars))\n",
    "    \n",
    "    # get mask for sampling context\n",
    "    instance_id_mask = np.zeros(data.shape[0]).astype(bool)\n",
    "    instance_id_mask[sampling_ctx.instance_ids] = True\n",
    "\n",
    "    # filter instance ids according to sampling context\n",
    "    sample_ids &= instance_id_mask\n",
    "\n",
    "    # sample\n",
    "    data[sample_ids, list(leaf_node.scope.query)] = np.random.normal(leaf_node.mean, leaf_node.std, sample_ids.sum())\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aafff67a",
   "metadata": {},
   "source": [
    "### Product Nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4547cfed",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProductNode(Node):\n",
    "    \"\"\"Simple SPN product node. Child nodes (explicit or implicit) are assumed to have pairwise disjoint scopes.\n",
    "    \n",
    "    Args:\n",
    "        children: list of child modules.\n",
    "    \"\"\"\n",
    "    def __init__(self, children: List[Module]) -> None:\n",
    "        \n",
    "        if(len(children) == 0):\n",
    "            raise ValueError(f\"List of child modules for ProductNode is empty.\")\n",
    "\n",
    "        super(ProductNode, self).__init__(children)\n",
    "\n",
    "@dispatch(ProductNode, dispatch_ctx=DispatchContext)\n",
    "@memoize\n",
    "def scope(product_node: ProductNode, dispatch_ctx: DispatchContext) -> ScopeArray:\n",
    "    \"\"\"Returns merged child scopes.\"\"\" \n",
    "    scopes = np.concatenate([scope(child, dispatch_ctx=dispatch_ctx) for child in product_node.children], axis=1)\n",
    "    return scopes.sum(keepdims=True)\n",
    "\n",
    "@dispatch(ProductNode, np.ndarray, dispatch_ctx=DispatchContext)\n",
    "@memoize\n",
    "def likelihood(module: ProductNode, data: np.ndarray, dispatch_ctx: DispatchContext) -> np.ndarray:\n",
    "    \"\"\"Returns the product of the child likelihoods.\"\"\"\n",
    "    inputs = np.concatenate([likelihood(child, data, dispatch_ctx=dispatch_ctx) for child in module.children], axis=1)\n",
    "    return np.prod(inputs, axis=1, keepdims=True)\n",
    "\n",
    "@dispatch(ProductNode, np.ndarray, dispatch_ctx=DispatchContext, sampling_ctx=SamplingContext)\n",
    "@memoize\n",
    "def sample(product_node: ProductNode, data: np.ndarray, dispatch_ctx: DispatchContext, sampling_ctx: Optional[SamplingContext]=None) -> np.ndarray:\n",
    "    \"\"\"Samples from all branches (i.e. nodes/module outputs).\"\"\" \n",
    "    \n",
    "    if sampling_ctx:\n",
    "        if not sampling_ctx.is_valid(data, product_node):\n",
    "            # invalid sampling context\n",
    "            raise ValueError(f\"Specified sampling context is invalid for specified data array and module.\")\n",
    "    else:\n",
    "        # create sampling context (assume all instances and all output nodes are to be used)\n",
    "        sampling_ctx = SamplingContext(list(range(data.shape[0])), [[] for _ in range(data.shape[0])])\n",
    "\n",
    "    # sample from all branches (i.e. inputs)\n",
    "    for child in product_node.children:\n",
    "        # create sampling context for child (same instance ids but different output ids now for new module)\n",
    "        child_sampling_ctx = SamplingContext(sampling_ctx.instance_ids, [[] for _ in range(len(sampling_ctx.instance_ids))])\n",
    "        # sample from child\n",
    "        sample(child, data, dispatch_ctx=dispatch_ctx, sampling_ctx=child_sampling_ctx)\n",
    "        \n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71bbd8e1",
   "metadata": {},
   "source": [
    "### Sum Nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6d188995",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SumNode(Node):\n",
    "    \"\"\"Simple SPN sum node. All child nodes (explicit or implicit) are assumed to have the same scopes.\n",
    "    \n",
    "    Args:\n",
    "        children: list of child modules.\n",
    "    \"\"\" \n",
    "    def __init__(self, children: List[Module]) -> None:\n",
    "        \n",
    "        if(len(children) == 0):\n",
    "            raise ValueError(f\"List of child modules for SumNode is empty.\")\n",
    "        \n",
    "        super(SumNode, self).__init__(children)\n",
    "        \n",
    "        self.weights = np.random.rand(self.n_in)\n",
    "        self.weights /= self.weights.sum()\n",
    "\n",
    "@dispatch(SumNode, dispatch_ctx=DispatchContext)\n",
    "@memoize\n",
    "def scope(sum_node: SumNode, dispatch_ctx: DispatchContext) -> ScopeArray:\n",
    "    \"\"\"Returns merged child scopes.\"\"\"\n",
    "    scopes = np.concatenate([scope(child, dispatch_ctx=dispatch_ctx) for child in sum_node.children])\n",
    "    return scopes.sum(keepdims=True)\n",
    "\n",
    "@dispatch(SumNode, np.ndarray, dispatch_ctx=DispatchContext)\n",
    "@memoize\n",
    "def likelihood(sum_node: SumNode, data: np.ndarray, dispatch_ctx: DispatchContext) -> np.ndarray:\n",
    "    \"\"\"Returns the weighted sum of the child likelihoods.\"\"\"\n",
    "    inputs = np.concatenate([likelihood(child, data, dispatch_ctx=dispatch_ctx) for child in sum_node.children], axis=1)\n",
    "    return (sum_node.weights*inputs).sum(axis=1, keepdims=True)\n",
    "\n",
    "@dispatch(SumNode, np.ndarray, dispatch_ctx=DispatchContext, sampling_ctx=SamplingContext)\n",
    "@memoize\n",
    "def sample(sum_node: SumNode, data: np.ndarray, dispatch_ctx: DispatchContext, sampling_ctx: Optional[SamplingContext]=None) -> np.ndarray:\n",
    "    \"\"\"Samples a branch for each instance (taking likelihoods into account).\"\"\"\n",
    "\n",
    "    if sampling_ctx:\n",
    "        if not sampling_ctx.is_valid(data, sum_node):\n",
    "            # invalid sampling context\n",
    "            raise ValueError(f\"Specified sampling context is invalid for specified data array and module.\")\n",
    "    else:\n",
    "        # create sampling context (assume all instances and all output nodes are to be used)\n",
    "        sampling_ctx = SamplingContext(list(range(data.shape[0])), [[] for _ in range(data.shape[0])])\n",
    "\n",
    "    # get likelihoods for children (using cache; only use relevant instances to save computation)\n",
    "    child_likelihoods = np.concatenate([likelihood(child, data[sampling_ctx.instance_ids], dispatch_ctx=dispatch_ctx) for child in sum_node.children], axis=1)\n",
    "    \n",
    "    # sample branch for each instance id\n",
    "    choices = []\n",
    "    sampling_probs = child_likelihoods * sum_node.weights\n",
    "    \n",
    "    for probs in sampling_probs:\n",
    "        # normalize\n",
    "        probs_norm = probs * (1 / np.sum(probs))\n",
    "        choices.append(np.random.choice(list(range(probs.shape[0])), p=probs_norm))\n",
    "\n",
    "    choices = np.array(choices)\n",
    "\n",
    "    # get number of outputs per child module\n",
    "    child_num_outputs = np.array([child.n_out for child in sum_node.children])\n",
    "    child_cum_outputs = np.cumsum(child_num_outputs)\n",
    "\n",
    "    # for each unique sampled branch\n",
    "    for branch_id in np.unique(choices):\n",
    "        # group instances by sampled branch\n",
    "        child_sample_ids = np.where(choices == branch_id)[0]\n",
    "\n",
    "        # get corresponding child and output id for sampled branch\n",
    "        child_id, output_id = sum_node.input_to_output_id(branch_id)\n",
    "    \n",
    "        # sample from child\n",
    "        sample(sum_node.children[child_id], data, dispatch_ctx=dispatch_ctx, sampling_ctx=SamplingContext(child_sample_ids, [[output_id] for _ in range(len(child_sample_ids))]))\n",
    "        \n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fd8bd00",
   "metadata": {},
   "source": [
    "##### Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "719788a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample: [[-1.02077459]], Sample likelihood: [[0.2369446]]\n"
     ]
    }
   ],
   "source": [
    "l1 = LeafNode(Scope(SPN(), [0])) # leaf node with (scope 0)\n",
    "l2 = LeafNode(Scope(SPN(), [0])) # leaf node with (scope 0)\n",
    "s = SumNode(children=[l1,l2]) # sum node over both product nodes (scope 0)\n",
    "\n",
    "samples = sample(s)\n",
    "print(f\"Sample: {samples}, Sample likelihood: {likelihood(s, samples)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7a30fe6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample: [[ 0.44808323  1.34456184]\n",
      " [-1.40430639  0.36902538]\n",
      " [-0.10079911 -1.00715846]], Sample likelihood: [[0.05829788]\n",
      " [0.05546489]\n",
      " [0.09535568]]\n",
      "Scope: [[Scope({0, 1}|{})]]\n"
     ]
    }
   ],
   "source": [
    "l1 = LeafNode(Scope(SPN(), [0])) # leaf node with (scope 0)\n",
    "l2 = LeafNode(Scope(SPN(), [1])) # leaf node with (scope 1)\n",
    "p1 = ProductNode([l1,l2]) # product node over both leaf nodes (scope 0,1)\n",
    "p2 = ProductNode([l1,l2]) # product node over both leaf nodes (scope 0,1)\n",
    "s = SumNode(children=[p1,p2]) # sum node over both product nodes (scope 0,1)\n",
    "\n",
    "data = np.random.randn(3,2)\n",
    "\n",
    "samples = sample(s, data)\n",
    "print(f\"Sample: {samples}, Sample likelihood: {likelihood(s, samples)}\")\n",
    "print(f\"Scope: {scope(s)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "29c124d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Likelihood (w/o cache):\t\t[[0.02766286]]\n",
      "Likelihood (store cache):\t[[0.02766286]], matches stored value: True\n",
      "Likelihood (modified cache):\t[[1.]]\n"
     ]
    }
   ],
   "source": [
    "data = np.random.randn(1,2)\n",
    "\n",
    "# call without passing cache\n",
    "l = likelihood(s, data)\n",
    "print(f\"Likelihood (w/o cache):\\t\\t{l}\")\n",
    "\n",
    "# use cache this time\n",
    "ctx = DispatchContext()\n",
    "cache = ctx.cache\n",
    "l = likelihood(s, data, dispatch_ctx=ctx)\n",
    "print(f\"Likelihood (store cache):\\t{l}, matches stored value: {all(l == cache.likelihood[s])}\")\n",
    "\n",
    "# set cache to check if stored value is used\n",
    "cache.likelihood[s] = np.ones((1,1))\n",
    "l = likelihood(s, data, dispatch_ctx=ctx)\n",
    "print(f\"Likelihood (modified cache):\\t{l}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a921dfc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Without any specifications: (1, 1)\n",
      "Specifying number of samples: (5, 1)\n",
      "Passing data tensor: True\n"
     ]
    }
   ],
   "source": [
    "l = LeafNode(Scope(SPN(), [0]))\n",
    "\n",
    "s = sample(l)\n",
    "print(\"Without any specifications:\", s.shape)\n",
    "\n",
    "s = sample(l, 5)\n",
    "print(\"Specifying number of samples:\", s.shape)\n",
    "\n",
    "s = np.full((3,1), np.nan)\n",
    "s_ = sample(l, s)\n",
    "\n",
    "# make sure that all nan values are now replaced (i.e. sampled) and matches the returned tensor (filled in-place)\n",
    "print(\"Passing data tensor:\", all(s == s_) and not any(np.isnan(s_)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70ecb375",
   "metadata": {},
   "source": [
    "## Nested Modules\n",
    "\n",
    "We'd like to build more complex modules from basic nodes. These could then again be combined to create even more intricate modules. For that we need to be able to nest modules.\n",
    "\n",
    "A network without any open non-terminal nodes/modules, can straight-forwardly be nested.\n",
    "\n",
    "However, non-terminal modules need child modules to be specified at creation. In nested modules this would require internal non-terminal modules to reference the same child modules as the enclosing module. This would be extremely messy.\n",
    "\n",
    "Instead, one could use placeholder modules that can stand-in for the actual children. The enclosing module can the set the cache for `scope`,`likelihood` calls to these modules or redirect `sample`-calls to the actual child modules. This also allows to divide up inputs from child modules for the internal/nested modules and change their order (in contrast to direct parent-child relationships).\n",
    "\n",
    "![nesting_module](uml/nesting_module.svg)\n",
    "\n",
    "**TODO**: find other/modern designation for `owner`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1ab400c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NestingModule(Module, ABC):\n",
    "    \"\"\"Convenient module class for nesting non-terminal modules.\n",
    "    \n",
    "    Args:\n",
    "        childen: list of child modules.\n",
    "    \"\"\"\n",
    "    def __init__(self, children: Optional[List[Module]]=None) -> None:\n",
    "        \n",
    "        if children is None:\n",
    "            children = []\n",
    "        \n",
    "        super(NestingModule, self).__init__(children)\n",
    "        self.placeholders = []\n",
    "\n",
    "    def create_placeholder(self, input_ids: List[int]) -> \"Placeholder\":\n",
    "        \"\"\"Creates a placholder module that can be used for internal non-terminal modules.\n",
    "        \n",
    "        Also registers the placeholder internally.\n",
    "        \"\"\"\n",
    "        # create and register placeholder\n",
    "        ph = self.Placeholder(self, input_ids)\n",
    "        self.placeholders.append(ph)\n",
    "\n",
    "        return ph\n",
    "    \n",
    "    def set_placeholders(self, cache, inputs) -> None:\n",
    "        \"\"\"Fills the cache for all registered placeholder modules given specified input values.\"\"\"\n",
    "        for ph in self.placeholders:\n",
    "            # fill placeholder cache with specified input values\n",
    "            cache[ph] = inputs[:,ph.input_ids]\n",
    "\n",
    "    class Placeholder(Module):\n",
    "        \"\"\"Placeholder module as an intermediary module between nested non-terminal modules and actual child modules.\"\"\"\n",
    "        def __init__(self, owner: Module, input_ids: List[int]) -> None:\n",
    "            self.owner = owner\n",
    "            self.input_ids = input_ids\n",
    "            \n",
    "            # compute conversion from input ids corresponding child and output id (Saves computation at run-time)\n",
    "            self.input_to_output_id_dict = {}\n",
    "            \n",
    "            for input_id in range(len(input_ids)):\n",
    "                # convert placeholder input id to actual input id\n",
    "                input_id_actual = self.input_ids[input_id]\n",
    "\n",
    "                # set corresponding child and output id via owner\n",
    "                self.input_to_output_id_dict[input_id] = self.owner.input_to_output_id(input_id_actual)\n",
    "\n",
    "        @property\n",
    "        def n_out(self) -> int:\n",
    "            return len(self.input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6ce91624",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dispatch(NestingModule.Placeholder, np.ndarray, dispatch_ctx=DispatchContext)\n",
    "@memoize\n",
    "def likelihood(nesting_module: NestingModule.Placeholder, data: np.ndarray, dispatch_ctx: DispatchContext) -> np.ndarray:\n",
    "    \"\"\"Gets called if values for placeholder module are not in the cache. In that case raise an error.\"\"\"\n",
    "    raise LookupError(\"Likelihood values for placeholder module not found in cache. Check if these are correctly set by the nesting module.\")\n",
    "\n",
    "@dispatch(NestingModule.Placeholder, dispatch_ctx=DispatchContext)\n",
    "@memoize\n",
    "def scope(nesting_module: NestingModule.Placeholder, dispatch_ctx: DispatchContext) -> np.ndarray:\n",
    "    \"\"\"Gets called if values for placeholder module are not in the cache. In that case raise an error.\"\"\"\n",
    "    raise LookupError(\"Scope values for placeholder module not found in cache. Check if these are correctly set by the nesting module.\")\n",
    "\n",
    "@dispatch(NestingModule.Placeholder, np.ndarray, dispatch_ctx=DispatchContext, sampling_ctx=SamplingContext)\n",
    "@memoize\n",
    "def sample(nesting_module: NestingModule.Placeholder, data: np.ndarray, dispatch_ctx: DispatchContext, sampling_ctx: Optional[SamplingContext]=None) -> np.ndarray:\n",
    "    \"\"\"Redirects sampling calls to sample actual child modules\"\"\"\n",
    "\n",
    "    if sampling_ctx:\n",
    "        if not sampling_ctx.is_valid(data, nesting_module):\n",
    "            # invalid sampling context\n",
    "            raise ValueError(f\"Specified sampling context is invalid for specified data array and module.\")\n",
    "    else:\n",
    "        if(nesting_module.n_out != 1):\n",
    "            raise ValueError(\"No sampling context specified. It is unclear which output to sample from.\")\n",
    "        else:\n",
    "            sampling_ctx = SamplingContext(list(range(len(data.shape[0]))), [[] for _ in len(data.shape[0])])\n",
    "\n",
    "    sampling_ctx_per_child = {}\n",
    "\n",
    "    # TODO: could potentially be done more efficiently via grouping\n",
    "    for instance_id, instance_output_ids in zip(sampling_ctx.instance_ids, sampling_ctx.output_ids):\n",
    "\n",
    "        output_per_child = {}\n",
    "        \n",
    "        # iterate over actual child and output ids\n",
    "        if instance_output_ids == []:\n",
    "            # all children\n",
    "        \n",
    "            for _, ids in nesting_module.input_to_output_id_dict.items():\n",
    "                output_per_child[ids[0]] = [ids[1]]\n",
    "        else:\n",
    "            for child_id, output_id in [nesting_module.input_to_output_id(output_id) for output_id in instance_output_ids]:\n",
    "\n",
    "                # sort output ids per child id\n",
    "                if(child_id in output_per_child):\n",
    "                    output_per_child[child_id].append(output_id)\n",
    "                else:\n",
    "                    output_per_child[child_id] = [output_id]\n",
    "        \n",
    "        # append (or create) sampling contexts\n",
    "        for child_id, output_ids in output_per_child.items():\n",
    "            if(child_id) in sampling_ctx_per_child:\n",
    "                sampling_ctx_per_child[child_id].instance_ids.append(instance_id)\n",
    "                sampling_ctx_per_child[child_id].output_ids.append(output_ids)\n",
    "            else:\n",
    "                sampling_ctx_per_child[child_id] = SamplingContext([instance_id], [output_ids])\n",
    "\n",
    "    # sample from children\n",
    "    for child_id, child_sampling_ctx in sampling_ctx_per_child.items():\n",
    "        sample(nesting_module.owner.children[child_id], data, dispatch_ctx=dispatch_ctx, sampling_ctx=child_sampling_ctx)\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df99f4a3",
   "metadata": {},
   "source": [
    "### Layer Modules\n",
    "\n",
    "Basic `LeafLayer`,`SumLayer` and `ProducLayer` classes.\n",
    "\n",
    "![layers](uml/layers.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69ad45cb",
   "metadata": {},
   "source": [
    "#### Leaf Layer\n",
    "\n",
    "Note: `LeafLayer` only contains terminal modules and therefore has no need for placeholders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "44c20160",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LeafLayer(Module):\n",
    "    \"\"\"Layer of multiple leaf nodes over the same scope.\n",
    "    \n",
    "    Args:\n",
    "        scope: scope of all leaf nodes.\n",
    "        n_out: number of leaf nodes.\n",
    "    \"\"\"\n",
    "    def __init__(self, scope: Scope, n_out) -> None:\n",
    "        \n",
    "        super(LeafLayer, self).__init__()\n",
    "        \n",
    "        self.nodes = []\n",
    "        self.scope = scope\n",
    "\n",
    "        # create leaf nodes\n",
    "        for _ in range(n_out):\n",
    "            self.nodes.append(LeafNode(scope=scope))\n",
    "    \n",
    "    @property\n",
    "    def n_out(self) -> int:\n",
    "        return len(self.nodes)\n",
    "\n",
    "@dispatch(LeafLayer, dispatch_ctx=DispatchContext)\n",
    "@memoize\n",
    "def scope(leaf_layer: LeafLayer, dispatch_ctx: DispatchContext) -> np.ndarray:\n",
    "    \"\"\"Concatenates the scopes of all leaf nodes.\"\"\"\n",
    "    return np.concatenate([scope(node, dispatch_ctx=dispatch_ctx) for node in leaf_layer.nodes], axis=1)\n",
    "\n",
    "@dispatch(LeafLayer, np.ndarray, dispatch_ctx=DispatchContext)\n",
    "@memoize\n",
    "def likelihood(leaf_layer: LeafLayer, data: np.ndarray, dispatch_ctx: DispatchContext) -> np.ndarray:\n",
    "    \"\"\"Concatenates the likelihoods for all leaf nodes.\"\"\"\n",
    "    return np.concatenate([likelihood(node, data, dispatch_ctx=dispatch_ctx) for node in leaf_layer.nodes], axis=1)\n",
    "\n",
    "@dispatch(LeafLayer, np.ndarray, dispatch_ctx=DispatchContext, sampling_ctx=SamplingContext)\n",
    "@memoize\n",
    "def sample(leaf_layer: LeafLayer, data: np.ndarray, dispatch_ctx: DispatchContext, sampling_ctx: Optional[SamplingContext]=None) -> np.ndarray:\n",
    "    \"\"\"Samples leaf nodes accoding to sampling context.\"\"\"\n",
    "\n",
    "    if sampling_ctx:\n",
    "        if not sampling_ctx.is_valid(data, leaf_layer):\n",
    "            # invalid sampling context\n",
    "            raise ValueError(f\"Specified sampling context is invalid for specified data array and module.\")\n",
    "    else:\n",
    "        raise ValueError(\"No sampling context specified. It is unclear which output to sample from.\")\n",
    "        # create sampling context (assume all instances and all output nodes are to be used)\n",
    "        #sampling_context = SamplingContext(list(range(data.shape[0])), [[] for _ in range(data.shape[0])])\n",
    "    \n",
    "    for node_ids in np.unique(sampling_ctx.output_ids, axis=0):\n",
    "        if(len(node_ids) != 1):\n",
    "            raise ValueError(\"Too many output ids specified for outputs over same scope.\")\n",
    "        \n",
    "        node_id = node_ids[0]\n",
    "        node_instance_ids = np.where(sampling_ctx.output_ids == node_ids)[0]\n",
    "        node_instance_ids_test = sampling_ctx.instance_ids\n",
    "        \n",
    "        sample(leaf_layer.nodes[node_id], data, dispatch_ctx=dispatch_ctx, sampling_ctx=SamplingContext(node_instance_ids_test, [[] for i in node_instance_ids]))\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68e9deae",
   "metadata": {},
   "source": [
    "##### Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c591b6d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Likelihood: (2, 3)\n",
      "Scope: [[Scope({0}|{}) Scope({0}|{}) Scope({0}|{})]]\n"
     ]
    }
   ],
   "source": [
    "layer = LeafLayer(Scope(SPN(), [0]), 3)\n",
    "\n",
    "data = np.random.randn(2,1)\n",
    "print(f\"Likelihood: {likelihood(layer, data).shape}\")\n",
    "\n",
    "print(f\"Scope: {scope(layer)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "759b7957",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.53034358]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = SumNode(children=[layer])\n",
    "sample(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b703ab1",
   "metadata": {},
   "source": [
    "#### Sum Layer\n",
    "\n",
    "Because this layer now uses non-terminal modules/nodes, we use `NestingModule` as a blueprint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d6f01414",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SumLayer(NestingModule):\n",
    "    \"\"\"Layer of multiple sum nodes over the same child modules.\n",
    "    \n",
    "    Args:\n",
    "        n_out: number of sum nodes.\n",
    "        children: list of child modules.\n",
    "    \"\"\"\n",
    "    def __init__(self, n_out: int, children: List[Module]) -> None:\n",
    "        super(SumLayer, self).__init__(children=children)\n",
    "        \n",
    "        self.nodes = []\n",
    "\n",
    "        # all nodes share the same input link here\n",
    "        ph = self.create_placeholder(list(range(self.n_in)))\n",
    "\n",
    "        for _ in range(n_out):\n",
    "            self.nodes.append(SumNode([ph]))\n",
    "\n",
    "    @property\n",
    "    def n_out(self) -> int:\n",
    "        return len(self.nodes)\n",
    "\n",
    "@dispatch(SumLayer, dispatch_ctx=DispatchContext)\n",
    "@memoize\n",
    "def scope(sum_layer: SumLayer, dispatch_ctx=DispatchContext) -> ScopeArray:\n",
    "    \"\"\"Concatenates the scopes of all sum nodes.\"\"\"    \n",
    "    input_scopes = np.concatenate([scope(child, dispatch_ctx=dispatch_ctx) for child in sum_layer.children], axis=1)\n",
    "\n",
    "    # set placeholders\n",
    "    sum_layer.set_placeholders(dispatch_ctx.cache.scope, input_scopes)\n",
    "    \n",
    "    # compute output scopes\n",
    "    output_scopes = np.concatenate([scope(node, dispatch_ctx=dispatch_ctx) for node in sum_layer.nodes], axis=1)\n",
    "    \n",
    "    return output_scopes\n",
    "\n",
    "@dispatch(SumLayer, np.ndarray, dispatch_ctx=DispatchContext)\n",
    "@memoize\n",
    "def likelihood(sum_layer: SumLayer, data: np.ndarray, dispatch_ctx: DispatchContext) -> np.ndarray:\n",
    "    \"\"\"Concatenates the likelihoods for all sum nodes.\"\"\"\n",
    "    input_likelihoods = np.concatenate([likelihood(child, data, dispatch_ctx=dispatch_ctx) for child in sum_layer.children], axis=1)\n",
    "    \n",
    "    # set placeholders\n",
    "    sum_layer.set_placeholders(dispatch_ctx.cache.likelihood, input_likelihoods)\n",
    "    \n",
    "    # compute output likelihoods\n",
    "    output_scopes = np.concatenate([likelihood(node, data, dispatch_ctx=dispatch_ctx) for node in sum_layer.nodes], axis=1)\n",
    "    \n",
    "    return output_scopes\n",
    "\n",
    "@dispatch(SumLayer, np.ndarray, dispatch_ctx=DispatchContext, sampling_ctx=SamplingContext)\n",
    "@memoize\n",
    "def sample(sum_layer: SumLayer, data: np.ndarray, dispatch_ctx: DispatchContext, sampling_ctx: Optional[SamplingContext]=None) -> np.ndarray:\n",
    "    \"\"\"Samples leaf nodes accoding to sampling context.\"\"\"\n",
    "\n",
    "    if sampling_ctx:\n",
    "        if not sampling_ctx.is_valid(data, sum_layer):\n",
    "            # invalid sampling context\n",
    "            raise ValueError(f\"Specified sampling context is invalid for specified data array and module.\")\n",
    "    else:\n",
    "        raise ValueError(\"No sampling context specified. It is unclear which output to sample from.\")\n",
    "\n",
    "    # fix for [] case\n",
    "    for node_ids in np.unique(sampling_ctx.output_ids, axis=0):\n",
    "        if(len(node_ids) != 1):\n",
    "            raise ValueError(\"Too many output ids specified for outputs over same scope.\")\n",
    "\n",
    "        node_id = node_ids[0]\n",
    "        node_instance_ids = np.where(sampling_ctx.output_ids == node_ids)[0]\n",
    "\n",
    "        sample(sum_layer.nodes[node_id], data, dispatch_ctx=dispatch_ctx, sampling_ctx=SamplingContext(node_instance_ids, [[] for i in node_instance_ids]))\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "518ade7d",
   "metadata": {},
   "source": [
    "##### Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1bb90377",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Likelihood: [[0.36744572 0.36744572 0.36744572]]\n",
      "Scope: [[Scope({0}|{}) Scope({0}|{}) Scope({0}|{})]]\n"
     ]
    }
   ],
   "source": [
    "leaf_layer = LeafLayer(Scope(SPN(), [0]), 3)\n",
    "sum_layer = SumLayer(3, [leaf_layer])\n",
    "\n",
    "data = np.random.randn(1,1)\n",
    "print(f\"Likelihood: {likelihood(sum_layer, data)}\")\n",
    "\n",
    "print(f\"Scope: {scope(sum_layer)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e48555d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample1: [nan]\n",
      "Sample2: [-0.00732721]\n"
     ]
    }
   ],
   "source": [
    "s_layer = SumNode([leaf_layer])\n",
    "s_nodes = SumNode([LeafNode(Scope(SPN(), [0])), LeafNode(Scope(SPN(), [0])), LeafNode(Scope(SPN(), [0]))])\n",
    "\n",
    "# TODO: there seems to be something wrong with sampling in LeafLayer\n",
    "print(f\"Sample1: {np.mean(sample(s_layer, 1000), axis=0)}\")\n",
    "print(f\"Sample2: {np.mean(sample(s_nodes, 1000), axis=0)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b486669",
   "metadata": {},
   "source": [
    "#### ProductLayer Class\n",
    "\n",
    "Number of `ProductNode`s is the number of combinations of elements from each input group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "83777d1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProductLayer(NestingModule):\n",
    "    \"\"\"Layer of multiple product nodes over the same child modules.\n",
    "    \n",
    "    Creates a product node for each combination of inputs from the child modules.\n",
    "    E.g. for two modules with 2 (ids 0,1) and 3 (ids 2,3,4) outputs, respectively, one gets nodes with the following inputs:\n",
    "        [0,2]\n",
    "        [0,3]\n",
    "        [0,4]\n",
    "        [1,2]\n",
    "        [1,3]\n",
    "        [1,4]\n",
    "\n",
    "    Args:\n",
    "        children: list of child modules.\n",
    "    \"\"\"\n",
    "    def __init__(self, children: List[Module]) -> None:\n",
    "        super(ProductLayer, self).__init__(children)\n",
    "        \n",
    "        self.nodes = []\n",
    "        self.input_placeholders = []\n",
    "        \n",
    "        children_n_out = [child.n_out for child in self.children]\n",
    "        total_ids = list(range(sum(children_n_out)))\n",
    "        factorized_ids = []\n",
    "        \n",
    "        for n in children_n_out:\n",
    "            factorized_ids.append(total_ids[:n])\n",
    "            total_ids = total_ids[n:]\n",
    "\n",
    "        self.input_ids_per_node = list(itertools.product(*factorized_ids))\n",
    "        \n",
    "        # create product nodes\n",
    "        for ids in self.input_ids_per_node:\n",
    "            ph = self.create_placeholder(list(ids))\n",
    "            self.nodes.append(ProductNode(children=[ph]))\n",
    "    \n",
    "    @property\n",
    "    def n_out(self) -> int:\n",
    "        return len(self.nodes)\n",
    "\n",
    "@dispatch(ProductLayer, dispatch_ctx=DispatchContext)\n",
    "@memoize\n",
    "def scope(product_layer: ProductLayer, dispatch_ctx: DispatchContext) -> np.ndarray:\n",
    "    \"\"\"Concatenates the scopes of all sum nodes.\"\"\"\n",
    "    input_scopes = np.concatenate([scope(child, dispatch_ctx=dispatch_ctx) for child in product_layer.children], axis=1)\n",
    "\n",
    "    # set placeholders\n",
    "    product_layer.set_placeholders(dispatch_ctx.cache.scope, input_scopes)\n",
    "\n",
    "    # compute output scopes\n",
    "    output_scopes = np.concatenate([scope(node, dispatch_ctx=dispatch_ctx) for node in product_layer.nodes], axis=1)\n",
    "\n",
    "    return output_scopes\n",
    "\n",
    "@dispatch(ProductLayer, np.ndarray, dispatch_ctx=DispatchContext)\n",
    "@memoize\n",
    "def likelihood(product_layer: ProductLayer, data: np.ndarray, dispatch_ctx: DispatchContext) -> np.ndarray:\n",
    "    \"\"\"Concatenates the likelihoods for all sum nodes.\"\"\"\n",
    "    input_likelihoods = np.concatenate([likelihood(child, data, dispatch_ctx=dispatch_ctx) for child in product_layer.children], axis=1)\n",
    "    \n",
    "    # set placeholders\n",
    "    product_layer.set_placeholders(dispatch_ctx.cache.likelihood, input_likelihoods)\n",
    "\n",
    "    # compute output likelihoods\n",
    "    output_scopes = np.concatenate([likelihood(node, data, dispatch_ctx=dispatch_ctx) for node in product_layer.nodes], axis=1)\n",
    "\n",
    "    return output_scopes\n",
    "\n",
    "@dispatch(ProductLayer, np.ndarray, dispatch_ctx=DispatchContext, sampling_ctx=SamplingContext)\n",
    "@memoize\n",
    "def sample(product_layer: ProductLayer, data: np.ndarray, dispatch_ctx: DispatchContext, sampling_ctx: Optional[SamplingContext]=None) -> np.ndarray:\n",
    "    \"\"\"Samples leaf nodes accoding to sampling context.\"\"\"\n",
    "\n",
    "    if sampling_ctx:\n",
    "        if not sampling_ctx.is_valid(data, product_layer):\n",
    "            # invalid sampling context\n",
    "            raise ValueError(f\"Specified sampling context is invalid for specified data array and module.\")\n",
    "    else:\n",
    "        raise ValueError(\"No sampling context specified. It is unclear which output to sample from.\")\n",
    "\n",
    "\n",
    "    for node_ids in np.unique(sampling_ctx.output_ids, axis=0):\n",
    "        if(len(node_ids) != 1):\n",
    "            raise ValueError(\"Too many output ids specified for outputs over same scope.\")\n",
    "\n",
    "        node_id = node_ids[0]\n",
    "        node_instance_ids = np.where(sampling_ctx.output_ids == node_ids)[0]\n",
    "        sample(product_layer.nodes[node_id], data, dispatch_ctx=dispatch_ctx, sampling_ctx=SamplingContext(node_instance_ids, [[] for i in node_instance_ids]))\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6deba26b",
   "metadata": {},
   "source": [
    "##### Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "49191d4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Likelihood: [[0.1504239 0.1504239 0.1504239 0.1504239]]\n",
      "Scope: [[Scope({0, 1}|{}) Scope({0, 1}|{}) Scope({0, 1}|{}) Scope({0, 1}|{})]]\n"
     ]
    }
   ],
   "source": [
    "leaf_layer_1 = LeafLayer(Scope(SPN(), [0]), 2)\n",
    "leaf_layer_2 = LeafLayer(Scope(SPN(), [1]), 2)\n",
    "product_layer = ProductLayer([leaf_layer_1, leaf_layer_2])\n",
    "\n",
    "data = np.random.randn(1,2)\n",
    "print(f\"Likelihood: {likelihood(product_layer, data)}\")\n",
    "\n",
    "print(f\"Scope: {scope(product_layer)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7878823c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Likelihood: [[0.06895548]]\n",
      "Scope: [[Scope({0, 1}|{})]]\n"
     ]
    }
   ],
   "source": [
    "l1 = LeafLayer(Scope(SPN(), [0]), n_out=3)\n",
    "s1 = SumLayer(3, [l1])\n",
    "\n",
    "l2 = LeafLayer(Scope(SPN(), [1]), n_out=3)\n",
    "s2 = SumLayer(3, [l2])\n",
    "\n",
    "p = ProductLayer([s1,s2])\n",
    "s = SumNode([p])\n",
    "\n",
    "data = np.random.randn(1,2)\n",
    "print(f\"Likelihood: {likelihood(s, data)}\")\n",
    "\n",
    "print(f\"Scope: {scope(s)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "dd7a841d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.93164701, -1.77439365]])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22596310",
   "metadata": {},
   "source": [
    "## Networks\n",
    "\n",
    "We could now build even more complex modules or networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "0d065018",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExampleNetwork(NestingModule):\n",
    "    \"\"\"Example network using layers and nodes.\n",
    "    \n",
    "    Args:\n",
    "        children: list of child modules.\n",
    "    \"\"\"\n",
    "    def __init__(self, children: List[Module]) -> None:\n",
    "        super(ExampleNetwork, self).__init__(children)\n",
    "        \n",
    "        n_ins = [child.n_out for child in self.children]\n",
    "        placeholders = []\n",
    "        \n",
    "        total_ids = range(sum(n_ins))\n",
    "\n",
    "        for n in n_ins:\n",
    "            placeholders.append(self.create_placeholder(total_ids[:n]))\n",
    "            total_ids = total_ids[n:]\n",
    "        \n",
    "        # create product layer on top\n",
    "        self.product_layer = ProductLayer(children=placeholders)\n",
    "        \n",
    "        # sum over all product layers\n",
    "        self.sum_node = SumNode(children=[self.product_layer])\n",
    "    \n",
    "    @property\n",
    "    def n_out(self) -> int:\n",
    "        return 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "542f66b0",
   "metadata": {},
   "source": [
    "In this case we can dispatch to the sum node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b8e60788",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dispatch(ExampleNetwork, dispatch_ctx=DispatchContext)\n",
    "@memoize\n",
    "def scope(example_network: ExampleNetwork, dispatch_ctx: DispatchContext) -> np.ndarray:\n",
    "    # compute input scopes\n",
    "    input_scopes = np.concatenate([scope(child, dispatch_ctx=dispatch_ctx) for child in example_network.children], axis=1)\n",
    "\n",
    "    # set placeholders\n",
    "    example_network.set_placeholders(dispatch_ctx.cache.scope, input_scopes)\n",
    "    \n",
    "    return scope(example_network.sum_node, dispatch_ctx=dispatch_ctx)\n",
    "\n",
    "@dispatch(ExampleNetwork, np.ndarray, dispatch_ctx=DispatchContext)\n",
    "@memoize\n",
    "def likelihood(example_network: ExampleNetwork, data: np.ndarray, dispatch_ctx: DispatchContext) -> np.ndarray:\n",
    "    # compute input likelihoods\n",
    "    input_likelihoods = np.concatenate([likelihood(child, data, dispatch_ctx=dispatch_ctx) for child in example_network.children], axis=1)\n",
    "    \n",
    "    # set placeholders\n",
    "    example_network.set_placeholders(dispatch_ctx.cache.likelihood, input_likelihoods)\n",
    "    \n",
    "    return likelihood(example_network.sum_node, data, dispatch_ctx=dispatch_ctx)\n",
    "\n",
    "@dispatch(ExampleNetwork, np.ndarray, dispatch_ctx=DispatchContext, sampling_ctx=SamplingContext)\n",
    "@memoize\n",
    "def sample(example_network: ExampleNetwork, data: np.ndarray, dispatch_ctx: DispatchContext, sampling_ctx: Optional[SamplingContext]=None) -> np.ndarray:\n",
    "    likelihood(example_network, data, dispatch_ctx=dispatch_context)\n",
    "    return sample(example_network.sum_node, data, dispatch_ctx=dispatch_context, sampling_ctx=sampling_ctx)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca0807c9",
   "metadata": {},
   "source": [
    "##### Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "1fabb209",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Likelihoods: [[0.04025569]\n",
      " [0.02779345]]\n",
      "Scope: [[Scope({0, 1, 2}|{})]]\n"
     ]
    }
   ],
   "source": [
    "leaf_layers = [LeafLayer(Scope(SPN(), [i]), 2) for i in range(3)]\n",
    "net = ExampleNetwork(children=leaf_layers)\n",
    "\n",
    "data = np.random.rand(2,3)\n",
    "\n",
    "print(f\"Likelihoods: {likelihood(net, data)}\")\n",
    "print(f\"Scope: {scope(net)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e7acae7",
   "metadata": {},
   "source": [
    "## Conditional Modules\n",
    "\n",
    "One might want to create conditional modules, e.g. modules where parameters are conditioned on some inputs and set accordingly.\n",
    "\n",
    "We would like to have two different ways of retrieving/setting conditional parameters:\n",
    "\n",
    "1. Self-contained as part of the module\n",
    "2. Injecting values from the outside (e.g. cached values or values computed as part of an overlying module)\n",
    "\n",
    "Additionally, we would like to avoid actually setting parameters, since parameters values are only valid for a given call and must be cleared afterwards. One solution would be to pass down values.The `args` dictionary in `DispatchContext` can be used to pass arguments to the `likelihood`,`scope` and `sample` calls of individual modules.\n",
    "\n",
    "Modules should check/retrieve parameters in the following order:\n",
    "\n",
    "1. Check if required parameters are specified in `DispatchContext`\n",
    "2. Check if an (alternative) function `cond_f` is specified as an argument for the module in `DispatchContext`\n",
    "3. Check if a `cond_f` function is specified in the module itself\n",
    "4. Raise exception"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a48d3209",
   "metadata": {},
   "source": [
    "#### Conditional Leaf Node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c290f557",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Callable\n",
    "\n",
    "class CondLeafNode(Node):\n",
    "    \"\"\"Basic conditional univariate leaf node. Here, implemented as a Gaussian.\n",
    "\n",
    "    Args:\n",
    "        scope: scope of the distribution.\n",
    "    \"\"\"\n",
    "    def __init__(self, scope: Scope, cond_f: Optional[Callable]=None) -> None:\n",
    "        \n",
    "        if(len(scope) != 1):\n",
    "            raise ValueError(\"Scope to large for univariate leaf node.\")\n",
    "        \n",
    "        super(CondLeafNode, self).__init__()\n",
    "        \n",
    "        self.scope = scope\n",
    "        self.cond_f = cond_f\n",
    "    \n",
    "    def set_cond_f(self, cond_f):\n",
    "        self.cond_f = cond_f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "bac6f21e",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dispatch(CondLeafNode, dispatch_ctx=DispatchContext)\n",
    "@memoize\n",
    "def scope(cond_leaf_node: CondLeafNode, dispatch_ctx: DispatchContext) -> np.ndarray:\n",
    "    \"\"\"Simply returns the scope of the module, since it's a leaf node.\"\"\"\n",
    "    return ScopeArray([[cond_leaf_node.scope]])\n",
    "\n",
    "@dispatch(CondLeafNode, np.ndarray, dispatch_ctx=DispatchContext)\n",
    "@memoize\n",
    "def likelihood(cond_leaf_node: CondLeafNode, data: np.ndarray, dispatch_ctx: DispatchContext) -> np.ndarray:\n",
    "    \"\"\"Returns the likelihood for each data instance. Marginalizes (likelihood of 1) for NaN values.\"\"\"\n",
    "\n",
    "    # ----- get conditional parameters -----\n",
    "\n",
    "    # check if argument dictionary first\n",
    "    if cond_leaf_node in dispatch_ctx.args:\n",
    "        args = dispatch_ctx.args[cond_leaf_node]\n",
    "\n",
    "        if \"mean\" in args and \"stdev\" in args:\n",
    "            mean = args[\"mean\"]\n",
    "            stdev = args[\"stdev\"]\n",
    "        \n",
    "        elif \"cond_f\" in args:\n",
    "            cond_f = args[\"cond_f\"]\n",
    "\n",
    "    # otherwise use conditional parameter function\n",
    "    elif cond_leaf_node.cond_f:\n",
    "        cond_f = cond_leaf_node.cond_f\n",
    "        params = cond_f(data)\n",
    "\n",
    "        # select parameters\n",
    "        mean = params[\"mean\"]\n",
    "        stdev = params[\"stdev\"]\n",
    "        \n",
    "        if cond_leaf_node in dispatch_ctx.args:\n",
    "            # update arguments for possible future (re)use\n",
    "            dispatch_ctx.args[cond_leaf_node].update(params)\n",
    "        else:\n",
    "            dispatch_ctx.args[cond_leaf_node] = params\n",
    "    else:\n",
    "        raise ValueError(\"Conditional leaf requires mean and standard deviation values are neither given nor is a computation function specified.\")\n",
    "\n",
    "    # check whether or not there are enough parameters given the data array\n",
    "    if mean.shape != (data.shape[0],1):\n",
    "        raise ValueError(\"Obtained values for mean of the conditional leaf are of wrong shape.\")\n",
    "    if stdev.shape != (data.shape[0],1):\n",
    "        raise ValueError(\"Obtained values for standard deviation of the conditional leaf are of wrong shape.\")\n",
    "    \n",
    "    dist = norm(mean, stdev)\n",
    "\n",
    "    likelihoods = np.ones((data.shape[0], len(cond_leaf_node.scope)))\n",
    "    inputs = data[:, list(cond_leaf_node.scope.query)]\n",
    "\n",
    "    marg_ids = np.isnan(inputs).sum(axis=1) == len(cond_leaf_node.scope)\n",
    "    likelihoods[~marg_ids, :] = dist.pdf(inputs[~marg_ids, :])\n",
    "\n",
    "    return likelihoods\n",
    "\n",
    "@dispatch(CondLeafNode, np.ndarray, dispatch_ctx=DispatchContext, sampling_ctx=SamplingContext)\n",
    "@memoize\n",
    "def sample(cond_leaf_node: CondLeafNode, data: np.ndarray, dispatch_ctx: DispatchContext, sampling_ctx: Optional[SamplingContext]=None) -> np.ndarray:\n",
    "    raise NotImplementedError"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "369589da",
   "metadata": {},
   "source": [
    "##### Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b75e96b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "cond_f = lambda data : {\"mean\": np.zeros((5,1)), \"stdev\": np.ones((5,1))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ab12e14a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cond_l1 = CondLeafNode(Scope(SPN(), [0], [1])) # leaf node (scope 0)\n",
    "cond_l2 = CondLeafNode(Scope(SPN(), [0], [1]), cond_f) # leaf node with conditional parameter function (scope 0)\n",
    "s = SumNode(children=[cond_l1, cond_l2]) # sum node over both product nodes (scope 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "29d93215",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conditional leaf requires mean and standard deviation values are neither given nor is a computation function specified.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    # should result in an error because no conditional paramters are specified (and no function to compute them is specified)\n",
    "    likelihood(cond_l1, data)\n",
    "except ValueError as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "7813c7e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# provide conditional paramters for the first conditional leaf\n",
    "ctx = DispatchContext()\n",
    "ctx.args[cond_l1] = {\n",
    "    \"mean\": np.zeros((5,1)),\n",
    "    \"stdev\": np.ones((5,1))\n",
    "}\n",
    "data = np.tile([0.0, 1.0], (5,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "6fcf5d5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Likelihood: [[0.39894228]\n",
      " [0.39894228]\n",
      " [0.39894228]\n",
      " [0.39894228]\n",
      " [0.39894228]]\n"
     ]
    }
   ],
   "source": [
    "print(f\"Likelihood: {likelihood(s, data, dispatch_ctx=ctx)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e994f7a",
   "metadata": {},
   "source": [
    "#### Conditional Sum Node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "5e3cdc66",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CondSumNode(Node):\n",
    "    \"\"\"Simple conditional sum node. All child nodes (explicit or implicit) are assumed to have the same scopes.\n",
    "    \n",
    "    Args:\n",
    "        children: list of child modules.\n",
    "    \"\"\" \n",
    "    def __init__(self, children: List[Module], cond_f: Optional[Callable]=None) -> None:\n",
    "\n",
    "        if(len(children) == 0):\n",
    "            raise ValueError(f\"List of child modules for SumNode is empty.\")\n",
    "\n",
    "        super(CondSumNode, self).__init__(children)\n",
    "\n",
    "        self.cond_f = cond_f\n",
    "\n",
    "    def set_cond_f(self, cond_f):\n",
    "        self.cond_f = cond_f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "31abc6de",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dispatch(CondSumNode, dispatch_ctx=DispatchContext)\n",
    "@memoize\n",
    "def scope(cond_sum_node: CondSumNode, dispatch_ctx: DispatchContext) -> ScopeArray:\n",
    "    \"\"\"Returns merged child scopes.\"\"\"\n",
    "    scopes = np.concatenate([scope(child, dispatch_ctx=dispatch_ctx) for child in cond_sum_node.children])\n",
    "    return scopes.sum(keepdims=True)\n",
    "\n",
    "@dispatch(CondSumNode, np.ndarray, dispatch_ctx=DispatchContext)\n",
    "@memoize\n",
    "def likelihood(cond_sum_node: CondSumNode, data: np.ndarray, dispatch_ctx: DispatchContext) -> np.ndarray:\n",
    "    \"\"\"Returns the weighted sum of the child likelihoods.\"\"\"\n",
    "\n",
    "    inputs = np.concatenate([likelihood(child, data, dispatch_ctx=dispatch_ctx) for child in cond_sum_node.children], axis=1)\n",
    "    \n",
    "    # ----- get conditional parameters -----\n",
    "\n",
    "    # check if argument dictionary first\n",
    "    if cond_sum_node in dispatch_ctx.args:\n",
    "        args = dispatch_ctx.args[cond_sum_node]\n",
    "\n",
    "        if \"weights\" in args:\n",
    "            weights = args[\"weights\"]\n",
    "        \n",
    "        elif \"cond_f\" in args:\n",
    "            cond_f = args[\"cond_f\"]\n",
    "\n",
    "    # otherwise use conditional parameter function\n",
    "    elif cond_sum_node.cond_f:\n",
    "        cond_f = cond_sum_node.cond_f\n",
    "        params = cond_f(data)\n",
    "\n",
    "        # select parameters\n",
    "        weights = params[\"weights\"]\n",
    "\n",
    "        if cond_sum_node in dispatch_ctx.args:\n",
    "            # update arguments for possible future (re)use\n",
    "            dispatch_ctx.args[cond_sum_node].update(params)\n",
    "        else:\n",
    "            dispatch_ctx.args[cond_sum_node] = params\n",
    "    else:\n",
    "        raise ValueError(\"Conditional sum node requires weigth values that are neither given nor is a computation function specified.\")\n",
    "\n",
    "    # check whether or not there are enough parameters given the data array\n",
    "    if weights.shape != (data.shape[0],1): # TODO\n",
    "        raise ValueError(\"Obtained values for weights of the conditional sum node are of wrong shape.\")\n",
    "\n",
    "    return (weights*inputs).sum(axis=1, keepdims=True)\n",
    "\n",
    "@dispatch(CondSumNode, np.ndarray, dispatch_ctx=DispatchContext, sampling_ctx=SamplingContext)\n",
    "@memoize\n",
    "def sample(cond_sum_node: CondSumNode, data: np.ndarray, dispatch_ctx: DispatchContext, sampling_ctx: Optional[SamplingContext]=None) -> np.ndarray:\n",
    "    \"\"\"Samples a branch for each instance (taking likelihoods into account).\"\"\"\n",
    "\n",
    "    if sampling_ctx:\n",
    "        if not sampling_ctx.is_valid(data, cond_sum_node):\n",
    "            # invalid sampling context\n",
    "            raise ValueError(f\"Specified sampling context is invalid for specified data array and module.\")\n",
    "    else:\n",
    "        # create sampling context (assume all instances and all output nodes are to be used)\n",
    "        sampling_ctx = SamplingContext(list(range(data.shape[0])), [[] for _ in range(data.shape[0])])\n",
    "\n",
    "    # get likelihoods for children (using cache; only use relevant instances to save computation)\n",
    "    child_likelihoods = np.concatenate([likelihood(child, data[sampling_ctx.instance_ids], dispatch_ctx=dispatch_ctx) for child in module.children], axis=1)\n",
    "    \n",
    "    # sample branch for each instance id\n",
    "    choices = []\n",
    "    sampling_probs = child_likelihoods * cond_sum_node.weights\n",
    "    \n",
    "    for probs in sampling_probs:\n",
    "        # normalize\n",
    "        probs_norm = probs * (1 / np.sum(probs))\n",
    "        choices.append(np.random.choice(list(range(probs.shape[0])), p=probs_norm))\n",
    "\n",
    "    choices = np.array(choices)\n",
    "\n",
    "    # get number of outputs per child module\n",
    "    child_num_outputs = np.array([child.n_out for child in module.children])\n",
    "    child_cum_outputs = np.cumsum(child_num_outputs)\n",
    "\n",
    "    # for each unique sampled branch\n",
    "    for branch_id in np.unique(choices):\n",
    "        # group instances by sampled branch\n",
    "        child_sample_ids = np.where(choices == branch_id)[0]\n",
    "\n",
    "        # get corresponding child and output id for sampled branch\n",
    "        child_id, output_id = cond_sum_node.input_to_output_id(branch_id)\n",
    "    \n",
    "        # sample from child\n",
    "        sample(cond_sum_node.children[child_id], data, dispatch_ctx=dispatch_ctx, sampling_ctx=SamplingContext(child_sample_ids, [[output_id] for _ in range(len(child_sample_ids))]))\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "604015ba",
   "metadata": {},
   "source": [
    "#### Conditional Network\n",
    "\n",
    "Example of a conditional network that computes all parameters centrally and passes it down to all nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "b28b0d05",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CondNet(Module):\n",
    "    def __init__(self, cond_f: Optional[Callable]=None):\n",
    "        \n",
    "        super(CondNet, self).__init__()\n",
    "\n",
    "        self.cond_f = cond_f\n",
    "        \n",
    "        # conditional leaves over rv 0\n",
    "        self.l1 = CondLeafNode(Scope(SPN(), [0], [2]))\n",
    "        self.l2 = CondLeafNode(Scope(SPN(), [0], [2]))\n",
    "        \n",
    "        # conditional leaves over rv 1\n",
    "        self.l3 = CondLeafNode(Scope(SPN(), [1], [2]))\n",
    "        self.l4 = CondLeafNode(Scope(SPN(), [1], [2]))\n",
    "        \n",
    "        # conditional sum nodes\n",
    "        self.s1 = CondSumNode([self.l1, self.l2])\n",
    "        self.s2 = CondSumNode([self.l3, self.l4])\n",
    "        \n",
    "        # product node\n",
    "        self.p = ProductNode([self.s1, self.s2])\n",
    "        \n",
    "        self.cond_nodes = [self.l1, self.l2, self.l3, self.l4, self.s1, self.s2]\n",
    "    \n",
    "    @property\n",
    "    def n_out(self):\n",
    "        return 1\n",
    "    \n",
    "    def set_cond_f(self, cond_f):\n",
    "        self.cond_f = cond_f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "6f639c52",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dispatch(CondNet, dispatch_ctx=DispatchContext)\n",
    "@memoize\n",
    "def scope(cond_net: CondNet, dispatch_ctx: DispatchContext) -> ScopeArray:\n",
    "    \"\"\"Returns scope.\"\"\"\n",
    "    return scope(cond_net.p, dispatch_ctx=dispatch_ctx)\n",
    "\n",
    "@dispatch(CondNet, np.ndarray, dispatch_ctx=DispatchContext)\n",
    "@memoize\n",
    "def likelihood(cond_net: CondNet, data: np.ndarray, dispatch_ctx: DispatchContext) -> np.ndarray:\n",
    "    \"\"\"Returns likelihoods.\"\"\"\n",
    "    \n",
    "    # ----- get conditional parameters -----\n",
    "    \n",
    "    if not all(m in dispatch_ctx.args for m in cond_net.cond_nodes):\n",
    "        \n",
    "        if cond_net in dispatch_ctx.args and \"cond_f\" in dispatch_ctx.args[cond_net]:\n",
    "            args = dispatch_ctx.args[cond_net]\n",
    "            cond_f = args[\"cond_f\"]\n",
    "        elif cond_net.cond_f:\n",
    "            cond_f = cond_net.cond_f\n",
    "        else:\n",
    "            raise ValueError(\"Conditional network requires weigth values that are neither given nor is a computation function specified.\")\n",
    "\n",
    "        cond_params = cond_f(data)\n",
    "        \n",
    "        for m, p in zip(cond_net.cond_nodes, cond_params):\n",
    "            if m in dispatch_ctx.args:\n",
    "                dispatch_ctx.args[m].update(p)\n",
    "            else:\n",
    "                dispatch_ctx.args[m] = p\n",
    "\n",
    "    return likelihood(cond_net.p, data, dispatch_ctx=dispatch_ctx)\n",
    "\n",
    "@dispatch(CondNet, np.ndarray, dispatch_ctx=DispatchContext, sampling_ctx=SamplingContext)\n",
    "@memoize\n",
    "def sample(cond_net: CondNet, data: np.ndarray, dispatch_ctx: DispatchContext, sampling_ctx: Optional[SamplingContext]=None) -> np.ndarray:\n",
    "    \"\"\"Returns samples.\"\"\"\n",
    "    return sample(cond_net.p, data, dispatch_ctx=dispatch_ctx, sampling_ctx=sampling_ctx)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ca4ab47",
   "metadata": {},
   "source": [
    "##### Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "22a0a12d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cond_f(data: np.ndarray) -> np.ndarray:\n",
    "    \n",
    "    # leaf node parameters\n",
    "    l1_params = {\"mean\": np.zeros((data.shape[0],1)), \"stdev\": np.ones((data.shape[0],1))}\n",
    "    l2_params = {\"mean\": np.zeros((data.shape[0],1)), \"stdev\": np.ones((data.shape[0],1))}\n",
    "    l3_params = {\"mean\": np.zeros((data.shape[0],1)), \"stdev\": np.ones((data.shape[0],1))}\n",
    "    l4_params = {\"mean\": np.zeros((data.shape[0],1)), \"stdev\": np.ones((data.shape[0],1))}\n",
    "    \n",
    "    # sum node parameters\n",
    "    s1_params = {\"weights\": np.ones((data.shape[0],1))/2}\n",
    "    s2_params = {\"weights\": np.ones((data.shape[0],1))/2}\n",
    "    \n",
    "    return l1_params, l2_params, l3_params, l4_params, s1_params, s2_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "6e803e1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[Scope({0, 1}|{2})]], dtype=object)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = CondNet(cond_f)\n",
    "scope(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "98707363",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.12215624],\n",
       "       [0.1258246 ],\n",
       "       [0.0033484 ]])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = np.random.randn(3,2)\n",
    "likelihood(net, data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1906539",
   "metadata": {},
   "source": [
    "## TODOs/Open Questions\n",
    "\n",
    "* Some bug in `LeafLayer` when sampling.\n",
    "* Examples for optimized layers without explicit nodes.\n",
    "* Structural marginalization\n",
    "* Must make sure that likelihoods are computed in the very beginning and don't change (i.e. partly sampled data should not affect the likelihoods of the rest of the sampling routine)\n",
    "* Creating default sampling contexts, computing input (scopes, likelihoods) etc. could be handled via specific decorator for sampling, scope and likelihood computation\n",
    "* Sampling multiple non-disjoint outputs at the same time (e.g. different replicas in RAT-SPNs)\n",
    "* Case distinction for scopes (e.g. merging based on sum-node different than product node). So far, modules themselves would have to check scopes manually.\n",
    "* Scope variable order: e.g. for `LeafNode` the order of the scope might be important, but is a `set` here. For example, a multivariate Gaussian could be specified via scope `[0,1]` or `[1,0]`, depending on the desired order. Since the data is selected via the `set`, the order might be different from the specified `mean`,`std` values, which might not be what the user expects.\n",
    "* Creating sampling array during dispatch might have to take evidence scopes into account."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
